{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d293c18a-42f1-4962-aa13-e392aa481283",
   "metadata": {},
   "source": [
    "# Homework: 使用 LangChain，并调用 GPT API Key 实现文本摘要和翻译聊天助手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4815cfcc-2500-4d63-8a1a-20e59a966fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:12.236988Z",
     "iopub.status.busy": "2024-02-14T16:39:12.236988Z",
     "iopub.status.idle": "2024-02-14T16:39:15.164315Z",
     "shell.execute_reply": "2024-02-14T16:39:15.164315Z",
     "shell.execute_reply.started": "2024-02-14T16:39:12.236988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\miniconda3\\envs\\py311_llm_win\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain, TransformChain, LLMChain, SimpleSequentialChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be1b035-0f24-45e7-8268-a2e616118d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:15.164315Z",
     "iopub.status.busy": "2024-02-14T16:39:15.164315Z",
     "iopub.status.idle": "2024-02-14T16:39:15.170290Z",
     "shell.execute_reply": "2024-02-14T16:39:15.170290Z",
     "shell.execute_reply.started": "2024-02-14T16:39:15.164315Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义一个转换函数，输入是一个字典，输出也是一个字典。\n",
    "def transform_func(inputs: dict) -> dict:\n",
    "    # 从输入字典中获取\"text\"键对应的文本。\n",
    "    text = inputs[\"text\"]\n",
    "    if len(text) > 1000:\n",
    "        text = text[:1000] + \" ......\"\n",
    "    # 返回问题的文本，用\"input\"作为键。\n",
    "    return {\"input\": text}\n",
    "\n",
    "def create_transform_chain() -> TransformChain:\n",
    "    # 使用上述转换函数创建一个TransformChain对象。\n",
    "    # 定义输入变量为[\"text\"]，输出变量为[\"input\"]，并指定转换函数为transform_func。\n",
    "    transform_chain = TransformChain(\n",
    "        input_variables=[\"text\"], output_variables=[\"input\"], transform=transform_func\n",
    "    )\n",
    "    return transform_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623e7af-85cc-47eb-b899-45b03f4d7e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:15.170290Z",
     "iopub.status.busy": "2024-02-14T16:39:15.170290Z",
     "iopub.status.idle": "2024-02-14T16:39:15.191400Z",
     "shell.execute_reply": "2024-02-14T16:39:15.191400Z",
     "shell.execute_reply.started": "2024-02-14T16:39:15.170290Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def create_destination_chains():\n",
    "\n",
    "    summary_template = \"\"\"\n",
    "    你是一位卓越的文本摘要专家。\n",
    "    你擅长从复杂的文本中提炼核心信息，生成简明扼要的摘要。\n",
    "    当你面对某些不确定或难以理解的内容时，你会以透明的方式表达你的困惑。\n",
    "    \n",
    "    请根据下面内容编写文本摘要：\n",
    "    {input}\n",
    "    \"\"\"\n",
    "\n",
    "    translation_template = \"\"\"\n",
    "    你是一位优秀的翻译专家。\n",
    "    你擅长以清晰简洁的方式把英文翻译成中文，让内容易于理解。\n",
    "    当你遇到某些不确定或难以准确表达的内容时，你会诚实地表达你的疑惑。\n",
    "    \n",
    "    请把下面英文内容翻译成中文：\n",
    "    {input}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_infos = [\n",
    "        {\n",
    "            \"name\": \"文本摘要\",\n",
    "            \"description\": \"适用于回答文本摘要问题\",\n",
    "            \"prompt_template\": summary_template,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"英文翻译\",\n",
    "            \"description\": \"适用于回答英文翻译问题\",\n",
    "            \"prompt_template\": translation_template,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "    destination_chains = {}\n",
    "\n",
    "    # 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "    for p_info in prompt_infos:\n",
    "        name = p_info[\"name\"]  # 提取名称\n",
    "        prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "        # 创建PromptTemplate对象\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "        # 使用上述模板和llm对象创建LLMChain对象\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "        # 将新创建的chain对象添加到destination_chains字典中\n",
    "        destination_chains[name] = chain\n",
    "\n",
    "    return prompt_infos, destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9774e8-eb67-404b-99e1-5f5b14702ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:15.191400Z",
     "iopub.status.busy": "2024-02-14T16:39:15.191400Z",
     "iopub.status.idle": "2024-02-14T16:39:15.198897Z",
     "shell.execute_reply": "2024-02-14T16:39:15.198897Z",
     "shell.execute_reply.started": "2024-02-14T16:39:15.191400Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "def create_multi_prompt_chain() -> MultiPromptChain:\n",
    "    # 创建目标链\n",
    "    prompt_infos, destination_chains = create_destination_chains()\n",
    "    # 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "    destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "    # 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "    destinations_str = \"\\n\".join(destinations)\n",
    "    # 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "    router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "    # 创建路由的PromptTemplate\n",
    "    router_prompt = PromptTemplate(\n",
    "        template=router_template,\n",
    "        input_variables=[\"input\"],\n",
    "        output_parser=RouterOutputParser(),\n",
    "    )\n",
    "    # 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "    router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt, verbose=True)\n",
    "\n",
    "    # 创建一个默认的ConversationChain\n",
    "    default_chain = ConversationChain(llm=llm, output_key=\"text\", verbose=True)\n",
    "\n",
    "    # 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "    multi_prompt_chain = MultiPromptChain(\n",
    "        router_chain=router_chain,\n",
    "        destination_chains=destination_chains,\n",
    "        default_chain=default_chain,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    return multi_prompt_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0d43d4-4b54-494b-ace9-3afe1ef03ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:15.198897Z",
     "iopub.status.busy": "2024-02-14T16:39:15.198897Z",
     "iopub.status.idle": "2024-02-14T16:39:15.210467Z",
     "shell.execute_reply": "2024-02-14T16:39:15.210467Z",
     "shell.execute_reply.started": "2024-02-14T16:39:15.198897Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequential_chain() -> SimpleSequentialChain:\n",
    "    transform_chain = create_transform_chain()\n",
    "    multi_prompt_chain = create_multi_prompt_chain()\n",
    "    sequential_chain = SimpleSequentialChain(chains=[transform_chain, multi_prompt_chain])\n",
    "    return sequential_chain\n",
    "\n",
    "sequential_chain = create_sequential_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360c6d2a-853a-41b7-aa66-2cd7f7c244c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:15.358423Z",
     "iopub.status.busy": "2024-02-14T16:39:15.358423Z",
     "iopub.status.idle": "2024-02-14T16:39:20.387139Z",
     "shell.execute_reply": "2024-02-14T16:39:20.387139Z",
     "shell.execute_reply.started": "2024-02-14T16:39:15.358423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\miniconda3\\envs\\py311_llm_win\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "F:\\ProgramData\\miniconda3\\envs\\py311_llm_win\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "文本摘要: {'input': 'OpenAI公司宣布，正在测试ChatGPT的记忆能力。ChatGPT将记住用户在所有聊天中讨论过的事情，这可以避免重复信息，使未来的对话更有帮助。用户可以控制ChatGPT的记忆，可以明确告诉它记住某些东西，询问它记住了什么，也可以通过对话或设置告诉它忘记，还可以完全关闭记忆功能。OpenAI称，本周将向一小部分ChatGPT免费和Plus用户推出该功能。'}\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    你是一位卓越的文本摘要专家。\n",
      "    你擅长从复杂的文本中提炼核心信息，生成简明扼要的摘要。\n",
      "    当你面对某些不确定或难以理解的内容时，你会以透明的方式表达你的困惑。\n",
      "    \n",
      "    请根据下面内容编写文本摘要：\n",
      "    OpenAI公司宣布，正在测试ChatGPT的记忆能力。ChatGPT将记住用户在所有聊天中讨论过的事情，这可以避免重复信息，使未来的对话更有帮助。用户可以控制ChatGPT的记忆，可以明确告诉它记住某些东西，询问它记住了什么，也可以通过对话或设置告诉它忘记，还可以完全关闭记忆功能。OpenAI称，本周将向一小部分ChatGPT免费和Plus用户推出该功能。\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ChatGPT回复：\n",
      "\n",
      "OpenAI宣布正在测试ChatGPT的记忆能力，该功能能够记住用户在所有聊天中讨论过的内容。这将有助于避免重复信息，提高未来对话的效率。用户可以控制ChatGPT的记忆，包括明确告诉它记住或忘记某些内容，或者完全关闭记忆功能。该功能将在本周向少部分用户推出。\n"
     ]
    }
   ],
   "source": [
    "summary_question = \"\"\"\n",
    "请根据下面内容编写文本摘要：\n",
    "当地时间2月13日，OpenAI公司宣布，正在测试ChatGPT的记忆能力。ChatGPT将记住用户在所有聊天中讨论过的事情，这可以避免重复信息，\n",
    "使未来的对话更有帮助。用户可以控制ChatGPT的记忆，可以明确告诉它记住某些东西，询问它记住了什么，也可以通过对话或设置告诉它忘记，\n",
    "还可以完全关闭记忆功能。OpenAI称，本周将向一小部分ChatGPT免费和Plus用户推出该功能。\n",
    "\"\"\"\n",
    "\n",
    "response = sequential_chain.run(summary_question)\n",
    "print(f\"ChatGPT回复：\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1582c8be-94c6-44b8-8043-12683ebe025d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T16:39:20.387139Z",
     "iopub.status.busy": "2024-02-14T16:39:20.387139Z",
     "iopub.status.idle": "2024-02-14T16:39:25.232707Z",
     "shell.execute_reply": "2024-02-14T16:39:25.232707Z",
     "shell.execute_reply.started": "2024-02-14T16:39:20.387139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\miniconda3\\envs\\py311_llm_win\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "英文翻译: {'input': 'Please translate the following English content into Chinese: In the last three years, the largest dense deep learning models have grown over 1000x to reach hundreds of billions of parameters, while the GPU memory has only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has been supported primarily though system innovations that allow large models to fit in the aggregate GPU memory of multiple GPUs. However, we are getting close to the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit a trillion parameter model for training, and such clusters are simply out of reach for most data scientists. In addition, training models at that scale requires complex combinations of parallelism techniques that puts a big burden on the data scientists to refactor their model.'}\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    你是一位优秀的翻译专家。\n",
      "    你擅长以清晰简洁的方式把英文翻译成中文，让内容易于理解。\n",
      "    当你遇到某些不确定或难以准确表达的内容时，你会诚实地表达你的疑惑。\n",
      "    \n",
      "    请把下面英文内容翻译成中文：\n",
      "    Please translate the following English content into Chinese: In the last three years, the largest dense deep learning models have grown over 1000x to reach hundreds of billions of parameters, while the GPU memory has only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has been supported primarily though system innovations that allow large models to fit in the aggregate GPU memory of multiple GPUs. However, we are getting close to the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit a trillion parameter model for training, and such clusters are simply out of reach for most data scientists. In addition, training models at that scale requires complex combinations of parallelism techniques that puts a big burden on the data scientists to refactor their model.\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ChatGPT回复：\n",
      "在过去的三年里，最大的密集深度学习模型已经增长了1000倍以上，达到数千亿个参数，而GPU内存仅增长了5倍（16 GB到80 GB）。因此，模型规模的增长主要是通过系统创新来支持的，这些创新允许大型模型适用于多个GPU的集合内存。但是，我们已经接近了GPU内存的极限。为了训练一个拥有万亿个参数的模型，需要800个NVIDIA V100 GPU，而这样的集群对于大多数数据科学家来说根本无法实现。此外，以这样的规模训练模型需要复杂的并行技术组合，这给数据科学家带来了很大的负担，需要重构他们的模型。\n"
     ]
    }
   ],
   "source": [
    "translation_question = \"\"\"\n",
    "请把下面英文内容翻译成中文：\n",
    "In the last three years, the largest dense deep learning models have grown over 1000x to reach hundreds of billions \n",
    "of parameters, while the GPU memory has only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has \n",
    "been supported primarily though system innovations that allow large models to fit in the aggregate GPU memory of \n",
    "multiple GPUs. However, we are getting close to the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit \n",
    "a trillion parameter model for training, and such clusters are simply out of reach for most data scientists. \n",
    "In addition, training models at that scale requires complex combinations of parallelism techniques that puts a big \n",
    "burden on the data scientists to refactor their model.\n",
    "\"\"\"\n",
    "\n",
    "response = sequential_chain.run(translation_question)\n",
    "print(f\"ChatGPT回复：\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe66bc7-a54e-4d10-b7be-207b3fc6b3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
